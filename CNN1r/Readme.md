# CNN1r/Readme.md

## Summary / 要約
1. Train and predict as usual.
2. Re-train the model using train data of low predict probability, and re-predict the label of test data of low probability


1. 普通に学習と予測を行う
2. 予測の確率が低い訓練データを使って再学習し, 確率の低いテストデータの再予測をする

## Preparation / 準備
### Probabilities of right answers and wrong answers / 正しい答えと間違った答えの確率
![正しい答えと間違った答えの確率](./graph_proba1.svg)

![正しい答えと間違った答えの確率(拡大)](./graph_proba2.svg)

- 青い線 ; 正しい答えに対する確率
- 赤い線 ; 予測された確率 (`tf.keras.Sequential.predict_proba()`)のうち最大のもの

グラフは, 正しい答えに対する確率 (青い線の値) で逆順にソートしている. 確率が 0.5 を下回ると, 誤答が増えてくる. 自信を持って間違えている (赤い線の値が高い) 場合と, 迷っている (青い線と赤い線が同じくらいの値) 場合があることが分かる.

訓練データは答えが分かっているので, 正しい答えに対する確率が低い画像を識別できる. しかしテストデータは (当たり前だが) 正答が分からないので, テストデータから間違っていそうなデータだけ抽出して再予測することはできない.

対策として考えられるのは,

- 最大の確率が例えば 0.8 以下の全ての画像に対して, 再予測する
- 全部のテストデータに対して再予測し, 1 回目の予測結果とアンサンブル学習をする

### 確率の低い画像データ
![確率の低い画像データ](./ans_max_digit_image.svg)

正しい答えに対する確率が低いほうから, 150 個のデータを示す。左上が確率が高いほう, 右下が確率が低いほうで, 画像の上の数字は, 左側が正しい答え, 右側が確率が最大だった答え.

これらの画像データで学習すれば, これらの画像データに対する正答率は向上する. しかし, もともと確率が高かった正答の画像を, 誤った結果にしてしまう危険性もある.

### 確率の低いデータのラベルの分布
![確率の低いデータのラベルの分布](./label_low_probability.svg)

正答の確率の低い画像データ (低いほうから 150 個) で, ラベルごとの個数をプロット. x 軸は正答のラベル, y 軸は個数. 1, 4, 7, 9 のデータで, 誤りが多い.

### まとめ
- 予測を間違ったテストデータのみを抽出することはできないので, 再予測する場合は
  - 最大の確率が例えば 0.8 以下のすべての画像に対して再予測する
    - この場合，自信を持って間違えているデータは, 間違えたまま (あきらめ)
  - 全部のテストデータに対して再予測し, 1 回目の予測結果とアンサンブル学習をする
    - 例えば最初の予測で 3 回分, 再予測で 2 回分, 合計 5 回分のデータでアンサンブルするなど, 最初の予測の重みを重めにするなど, 工夫が必要か
